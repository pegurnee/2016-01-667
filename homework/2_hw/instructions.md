1.
  a. Find the gini measure of the grades distributed 6A, 10B, 4C.
  b. Find the shannon's entropy of the grades.
  c. Which of the following set of grades has the highest gini entropy and what is its entropy: {5A, 5B, 5C}, {6A, 5B, 4C}, {10A, 3B, 2C}
2.
  A B C class
  0 1 0 2
  1 0 1 3
  1 1 0 2
  1 1 1 2
  0 0 0 1
  a. What is the weighted average class entropy if A is used as the condition?
  b. What is the weighted average class entropy if B is used as the condition?
  c. What is the weighted average class entropy if C is used as the condition?
  d. Which is the best condition? Show the partition of records.
3.
  Consider the given training records. Show how the top node of the decision tree will be built. Show quality of possible conditions, best condition, and partition of records for best condition.
4.
  a. Show how the nodes will be built for the two partitions formed in question 3.
  b. Show quality of possible conditions, best condition, and partition of records for best condition.
  c. Show the final decision true.
5.
  3   2   10  | 2
  2   1   2   | 1
  5   18  9   | 2
  2   5   4   | 1
  4   3   2   | 1
  4   17  12  | 2
  a. Classify (6, 7, 10) using nearest neighbor classifier with euclidean distance, three neighbors, and weighted majority rule. Show distances, weights, and class selection.
  b. Classify (4, 9, 5) using nearest neighbor classifier with taxicab distance, four neighbors, and unweighted majority rule. Show distances and class selection.
6.
  gpa (0-4)   age (20-60)   score (500-1000)  class
  3.4         40            600               2
  2.8         25            800               1
  3.5         30            700               3
  3.0         45            650               2
  a. Show normalized records.
  b. Classify (3.2, 35, 700) using nearest neighbor classifier with euclidean distance, three neighbors, weighted majority rule. Show distances, weights, and class selection.
